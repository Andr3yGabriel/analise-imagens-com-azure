# analise-imagens-com-azure

Testando a ferramenta de análise de imagens do laboratório de visão computacional do Azure pude perceber como a maioria das descrições são bem simples e geralmente não se atentam a detalhes maiores fora o rosto ou o principal da imagem.
Na imagem Input_5, por exemplo, o programa somente detecta que estou utilizando óculos e chapéu mas não consegue identificar que seja uma selfie ou dá atenção a objetos como a mesa e o computador ao fundo.
Output_5:
<img width="775" alt="Output_5" src="https://github.com/Andr3yGabriel/analise-imagens-com-azure/assets/140266061/0e727602-633e-48ea-8127-d264db5e4fce">
Outro detalhe que notei foi o fato de o programa não identificar bem quantas pessoas tem na foto e então começa a descrever como simpelsmente um grupo, por exemplo, na imagem Input_1. Além disso ele não identifica bem as ações então não consegue dizer que as pessoas estão posando para uma foto ou beijando a bochecha.
<img width="756" alt="Output_1" src="https://github.com/Andr3yGabriel/analise-imagens-com-azure/assets/140266061/76d3314b-28f9-484f-9ef3-4a55eaf3e4ef">
